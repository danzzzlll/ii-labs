# Инструкция по использованию модели

## Шаг 1: Получение истории Телеграмм-чата

1. **Экспорт истории чата в Telegram:**
   - Откройте настройки Telegram.
   - Перейдите в раздел "Данные и память".
   - Нажмите на "Экспортировать историю чата".
   - Выберите чат, историю которого вы хотите экспортировать.
   - В настройках экспорта выберите формат "JSON (машинночитаемый)".
   - Начните процесс экспорта и дождитесь его завершения.
  
2. **Сохранение файла:**
   - Переместите скачанный файл в папку `data` на вашем компьютере.

3. **Преобразование JSON в CSV:**
   - Откройте терминал или командную строку.
   - Перейдите в директорию с вашим проектом.
   - Запустите следующую команду:
     ```sh
     python ./src/prepare_messages.py --tg-history-path './data/result.json' --output-path './data/data.csv'
     ```
   - Дождитесь окончания выполнения скрипта.

4. **Результат:**
   - В папке `data` появится файл `data.csv`, содержащий экспортированную историю чата в формате CSV с колонками `context_1`, `context_2`, `context_3`, `response`.

## Шаг 2: Подготовка данных и fine-tuning

1. **Очистка данных:**
   - Откройте файл `data.csv`.
   - Удалите лишние контексты, оставив только необходимые для обучения пары вида `context_1:input-response:output`.

2. **Токенизация данных:**
   - Используйте подходящий токенизатор для преобразования текста в токены.

3. **Загрузка модели:**
   - Загрузите предобученную модель,  `rugpt-3-small`.

4. **Дообучение модели:**
   - Настройте параметры дообучения и запустите процесс.

5. **Сохранение модели:**
   - Сохраните дообученную модель и токенизатор на платформе Hugging Face или локально.

## Шаг 3: Запуск модели

1. **Настройка окружения:**
   - Клонируйте репозиторий с кодом модели:
     ```sh
     git clone https://github.com/danzzzlll/ii-labs.git
     ```
   - Перейдите в папку проекта:
     ```sh
     cd path_to_project
     ```

2. **Создание виртуального окружения:**
   - Создайте виртуальное окружение:
     ```sh
     python -m venv venv_name
     ```
   - Активируйте виртуальное окружение:
     ```sh
     venv_name\Scripts\activate
     ```

3. **Установка зависимостей:**
   - Установите необходимые зависимости:
     ```sh
     pip install -r requirements.txt
     ```

4. **Запуск модели:**
   - Запустите скрипт:
     ```sh
     python ./src/run.py
     ```

   - После загрузки модели вы сможете взаимодействовать с ней, задавая вопросы. Обратите внимание на время ответа: на CPU оно может составлять 10-15 секунд, в то время как на GPU — 3-5 секунд.
